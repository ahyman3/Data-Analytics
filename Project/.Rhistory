#Any pattern with the sin or cos of Aspect
p2 <- ggplot(df, aes(x = cosAspect, y = sinAspect, color = Cover_Type))
#Scatter plot
p2 <- p2 + geom_point(alpha = 0.7) + ggtitle("Sine and Cosine of Aspect")
p2 <- p2 + xlab("Cosine of Aspect") + ylab("Sine of Aspect")
p2
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(dplyr)
library(tidyr)
library(klaR)
library(matrixStats)
library(rpart)
library(ggplot2)
library(rpart.plot)
library(randomForest)
library(e1071)
library(class)
library(arules)
library(reshape2)
p3 <- ggplot(df, aes(x = Slope, y = Elevation, color = Cover_Type))
p3 <- p3 + geom_point(alpha = 0.5) + ggtitle("Elevation vs. Slope")
p3
#How are the cover types distributed
soil <- df %>% dplyr::select(contains("Cover"), contains("Soil"))
head(soil)
#How are the cover types distributed
soil <- df %>% dplyr::select(contains("Cover"), contains("Soil")) %>%
gather(key = "Cover_Type")
head(soil)
#How are the cover types distributed
soil <- df %>% dplyr::select(contains("Cover"), contains("Soil")) %>%
gather(key = "Soil_Type", -"Cover_Type")
head(soil)
mini_iris <- iris[c(1, 51, 101), ]
gather(mini_iris, key = flower_att, value = measurement,
Sepal.Length, Sepal.Width, Petal.Length, Petal.Width)
#How are the cover types distributed
soil <- df %>% dplyr::select(contains("Cover"), contains("Soil")) %>%
gather(key = "Soil_Type", value = "Present", -Cover_Type)
head(soil)
?filter
#How are the cover types distributed
soil <- df %>% dplyr::select(contains("Cover"), contains("Soil")) %>%
gather(key = "Soil_Type", value = "Present", -Cover_Type) %>%
filter(Present > 0)
head(soil)
#How are the cover types distributed
soil <- df %>% dplyr::select(contains("Cover"), contains("Soil")) %>%
gather(key = "Soil_Type", value = "Present", -Cover_Type) %>%
filter(Present > 0) %>% dplyr::select(-Present)
head(soil)
soil.plot <- ggplot(soil, aes(x = Cover_Type, fill = Soil_Type))
soil.plot <- soil.plot + geom_bar()
soil.plot
soil.plot <- ggplot(soil, aes(x = Cover_Type, fill = Soil_Type))
soil.plot <- soil.plot + geom_bar() guides(fill=FALSE)
soil.plot <- ggplot(soil, aes(x = Cover_Type, fill = Soil_Type))
soil.plot <- soil.plot + geom_bar() + guides(fill=FALSE)
soil.plot
#How are the cover types distributed
soil <- df %>% dplyr::select(contains("Cover"), contains("Soil")) %>%
gather(key = "Soil_Type", value = "Present", -Cover_Type) %>%
filter(Present > 0) %>% dplyr::select(-Present)
soil.plot <- ggplot(soil, aes(x = Cover_Type, fill = Soil_Type))
soil.plot <- soil.plot + geom_bar() + guides(fill=FALSE)
soil.plot <- soil.plot +  xlab("Cover Type") + xlab("Count")
soil.plot <- soil.plot +  ggtitle("Soil Types of Forest Covers")
soil.plot
#How are the cover types distributed
soil <- df %>% dplyr::select(contains("Cover"), contains("Soil")) %>%
gather(key = "Soil_Type", value = "Present", -Cover_Type) %>%
filter(Present > 0) %>% dplyr::select(-Present)
soil.plot <- ggplot(soil, aes(x = Cover_Type, fill = Soil_Type))
soil.plot <- soil.plot + geom_bar() + guides(fill=FALSE)
soil.plot <- soil.plot +  xlab("Cover Type") + ylab("Count")
soil.plot <- soil.plot +  ggtitle("Soil Types of Forest Covers")
soil.plot
print(table(soil$Soil_Type, soil$Cover_Type))
#How are the cover types distributed
#formatting the data
soil <- df %>% dplyr::select(contains("Cover"), contains("Soil")) %>%
gather(key = "Soil_Type", value = "Present", -Cover_Type) %>%
filter(Present > 0) %>% dplyr::select(-Present)
#Plotting the soils in each of the cover types
soil.plot <- ggplot(soil, aes(x = Cover_Type, fill = Soil_Type))
soil.plot <- soil.plot + geom_bar() + guides(fill=FALSE)
soil.plot <- soil.plot +  xlab("Cover Type") + ylab("Count")
soil.plot <- soil.plot +  ggtitle("Soil Types of Forest Covers")
print(soil.plot)
#How are the cover types distributed
#formatting the data
soil <- df %>% dplyr::select(contains("Cover"), contains("Soil")) %>%
gather(key = "Soil_Type", value = "Present", -Cover_Type) %>%
filter(Present > 0) %>% dplyr::select(-Present)
#Plotting the soils in each of the cover types
soil.plot <- ggplot(soil, aes(x = Cover_Type, fill = Soil_Type))
soil.plot <- soil.plot + geom_bar() + guides(fill=FALSE)
soil.plot <- soil.plot +  xlab("Cover Type") + ylab("Count")
soil.plot <- soil.plot +  ggtitle("Soil Types of Forest Covers")
print(soil.plot)
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(dplyr)
library(tidyr)
library(klaR)
library(matrixStats)
library(rpart)
library(ggplot2)
library(rpart.plot)
library(randomForest)
library(e1071)
library(class)
library(arules)
library(reshape2)
#train control
tc <- trainControl(method = "cv", number = 3)
#default decision tree
dt <- train(Cover_Type ~ ., data = train_df, trControl = tc, method = "rpart",
tuneGrid = expand.grid(cp = c(0.005, 0.001, 0.0005, 0.0001)))
dt
#train control
tc <- trainControl(method = "cv", number = 3)
#default decision tree
dt <- train(Cover_Type ~ ., data = train_df, trControl = tc, method = "rpart",
tuneGrid = expand.grid(cp = c(0.005, 0.001, 0.0005, 0.0001)))
#looking at the the test set accuracy
preds <- predict(dt, test_df, "raw")
dt1.confmat <- confusionMatrix(preds, test_df$Cover_Type)
cat("Decision tree has an accuracy of", dt1.confmat$overall[1], "on hold out set\n\n")
dt1.confmat$table
#train control
tc <- trainControl(method = "cv", number = 3)
#default decision tree
dt <- train(Cover_Type ~ ., data = train_df, trControl = tc, method = "rpart",
tuneGrid = expand.grid(cp = c(0.01, 0.005, 0.001, 0.0005, 0.0001)))
#looking at the the test set accuracy
preds <- predict(dt, test_df, "raw")
dt1.confmat <- confusionMatrix(preds, test_df$Cover_Type)
cat("Decision tree has an accuracy of", dt1.confmat$overall[1], "on hold out set\n\n")
dt1.confmat$table
dt
#train control
tc <- trainControl(method = "cv", number = 3)
#default decision tree
dt <- train(Cover_Type ~ ., data = train_df, trControl = tc, method = "rpart",
tuneGrid = expand.grid(cp = c(0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005)))
#looking at the the test set accuracy
preds <- predict(dt, test_df, "raw")
dt1.confmat <- confusionMatrix(preds, test_df$Cover_Type)
cat("Decision tree has an accuracy of", dt1.confmat$overall[1], "on hold out set\n\n")
dt1.confmat$table
dt
?rpart
cat("Decision tree has an accuracy of", dt1.confmat$overall[1], "on hold out set\n\n")
dt1.confmat$table
#Random Forest
#training
rf <- train(Cover_Type ~ ., data = train_df, trControl = tc, method = "rf")
#cross-validation performance
rf   #cross-validation accuracy of 0.837 with mtry = 29
?randomForest
#Accuracy on the hold out set
preds <- predict(rf$finalModel, test_df, "response")
rf.confmat <- confusionMatrix(preds, test_df$Cover_Type)
cat("Random Forest has an accuracy of", rf.confmat$overall[1], "on hold out set\n\n")
rf.confmat$table
varImp(rf)
View(svm.grid)
head(varImp(rf). 10)
head(varImp(rf), 10)
varImp(rf)
#Vector of continous variables
cont.cols <- c("Elevation", "Aspect", "Slope", "Horizontal_Distance_To_Hydrology", "Vertical_Distance_To_Hydrology", "Horizontal_Distance_To_Roadways", "Hillshade_9am", "Hillshade_Noon", "Hillshade_3pm", "Horizontal_Distance_To_Fire_Points", "sinAspect", "cosAspect", "Euclidean_Distance_to_Hydrology")
#training DF with all binary and scaled continous variables
train.scaled <- train_df %>% dplyr::select(one_of(cont.cols)) %>%
scale %>% cbind(train_df[,! colnames(train_df) %in% cont.cols])
#Scaled testdf
test.scaled <- test_df %>% dplyr::select(one_of(cont.cols)) %>%
scale(center = as.matrix(colMeans(train_df[,cont.cols])), scale = colSds(as.matrix(train_df[,cont.cols]))) %>%
cbind(test_df[,! colnames(test_df) %in% cont.cols])
svm.linear   #cv-3 Accuracy of 0.716
svm.linear   #cv-3 Accuracy of 0.716
svm.poly   #cv-3 Accuracy of 0.782 scale - 0.2, C = 0.8
svm.poly   #cv-3 Accuracy of 0.782 scale - 0.2, C = 0.8
#Accuracy on hold out set
cat("SVM with Polynomial Kernel has an accuracy of", svm.confmat$overall[1], "on hold out set\n\n")
print(svm.confmat$table)
rf.confmat$table
#Evaluation
cat("KNN-1 has an accuracy of", knn1.confmat$overall[1], "on hold out set\n\n")
#Evaluation
cat("KNN-3 has an accuracy of", knn3.confmat$overall[1], "on hold out set\n\n")
#Evaluation
cat("KNN-5 has an accuracy of", knn5.confmat$overall[1], "on hold out set\n\n")
#Evaluation
cat("KNN-7 has an accuracy of", knn7.confmat$overall[1], "on hold out set\n\n")
#Evaluation
cat("KNN-9 has an accuracy of", knn9.confmat$overall[1], "on hold out set\n\n")
model_knn <- train(Cover_Type ~ ., data = train.scaled, method = "knn",
tuneGrid = data.frame(k = seq(1, 25)),
trControl = tc)
model_knn
#predicting the test set
pred <- predict(model_knn, test.scaled)
pred
#Confusion matrix
knn.conmat <- confusionMatrix(pred, test.scaled$Cover_Type)
cat("KNN w/ k = 1 has an accuracy of", knn.confmat$overall[1], "on hold out set\n\n")
#Confusion matrix
knn.confmat <- confusionMatrix(pred, test.scaled$Cover_Type)
cat("KNN w/ k = 1 has an accuracy of", knn.confmat$overall[1], "on hold out set\n\n")
knn.confmat$table
model_knn
cat("KNN w/ k = 1 has an accuracy of", knn.confmat$overall[1], "on hold out set\n\n")
cat("KNN w/ k = 1 has an accuracy of", knn.confmat$overall[1], "on hold out set\n\n")
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(dplyr)
library(tidyr)
library(klaR)
library(matrixStats)
library(rpart)
library(ggplot2)
library(rpart.plot)
library(randomForest)
library(e1071)
library(class)
library(arules)
library(reshape2)
#Random Forest was best model
test.all <- read.csv("test.csv")
#Random Forest was best model
test.all <- read.csv("test.csv")
#Feature engineering for the final test data
test.all <- test.all %>% mutate(sinAspect = sin(Aspect), cosAspect = cos(Aspect)) %>%
mutate(Euclidean_Distance_to_Hydrology =
sqrt(Vertical_Distance_To_Hydrology^2 + Horizontal_Distance_To_Hydrology^2))
test.all <- test.all %>% dplyr::select(one_of(cont.cols)) %>%
scale %>% cbind(train_df[,! colnames(train_df) %in% cont.cols])
#Feature engineering for the final test data
test.all <- test.all %>% mutate(sinAspect = sin(Aspect), cosAspect = cos(Aspect)) %>%
mutate(Euclidean_Distance_to_Hydrology =
sqrt(Vertical_Distance_To_Hydrology^2 + Horizontal_Distance_To_Hydrology^2))
test.final <- test.all %>% dplyr::select(one_of(cont.cols)) %>%
scale %>% cbind(train_df[,! colnames(test.all) %in% cont.cols])
#Random Forest was best model
test.all <- read.csv("test.csv")
#Feature engineering for the final test data
test.all <- test.all %>% mutate(sinAspect = sin(Aspect), cosAspect = cos(Aspect)) %>%
mutate(Euclidean_Distance_to_Hydrology =
sqrt(Vertical_Distance_To_Hydrology^2 + Horizontal_Distance_To_Hydrology^2))
test.final <- test.all %>% dplyr::select(one_of(cont.cols)) %>%
scale %>% cbind(train_df[,! colnames(test.all) %in% cont.cols])
test.final <- test.all %>% dplyr::select(one_of(cont.cols)) %>%
scale %>% cbind(test.all[,! colnames(test.all) %in% cont.cols])
#Predicting for test cases
predictions.test <- predict(svm.poly, test.all, "raw")
#Final data frame
final.predictions <- data.frame(Id = test.all$Id, Cover_Type = predictions.test)
write.csv(final.predictions, "submission.csv", row.names = F)
head(final.predictions)
head(final.predictions, 10)
head(final.predictions, 50)
#Predicting for test cases
predictions.test <- predict(svm.poly, test.all)
#Random Forest was best model
test.all <- read.csv("test.csv")
#Feature engineering for the final test data
test.all <- test.all %>% mutate(sinAspect = sin(Aspect), cosAspect = cos(Aspect)) %>%
mutate(Euclidean_Distance_to_Hydrology =
sqrt(Vertical_Distance_To_Hydrology^2 + Horizontal_Distance_To_Hydrology^2))
test.final <- test.all %>% dplyr::select(one_of(cont.cols)) %>%
scale(center = as.matrix(colMeans(train_df[,cont.cols])), scale = colSds(as.matrix(train_df[,cont.cols]))) %>%
cbind(test.all[,! colnames(test.all) %in% cont.cols])
#Predicting for test cases
predictions.test <- predict(svm.poly, test.final)
#Final data frame
final.predictions <- data.frame(Id = test.final$Id, Cover_Type = predictions.test)
write.csv(final.predictions, "submission.csv", row.names = F)
head(final.predictions)
head(final.predictions, 10)
?NaiveBayes
#Naive Bayes LaPlace factor of 2, KDE
nb2.kde <- NaiveBayes(Cover_Type ~ ., data = train.nb, fL = 2, usekernel = T)
preds <- predict(nb.kde, test.nb)
#Naive Bayes LaPlace factor of 2, KDE
nb2.kde <- NaiveBayes(Cover_Type ~ ., data = train.nb, fL = 2, usekernel = T)
preds <- predict(nb2.kde, test.nb)
#Naive Bayes LaPlace factor of 2, KDE
nb2.kde <- NaiveBayes(Cover_Type ~ ., data = train.nb, fL = 2, usekernel = T)
preds <- suppressWarnings(predict(nb2.kde, test.nb))
#Confusion Matrix for BB with laplace factor of 2
nb2.kde.confmat <- confusionMatrix(preds$class, test.nb$Cover_Type)
cat("Naive Bayes w/ KDE and fL = 2 has an accuracy of", nb2.kde.confmat$overall[1], "on hold out set\n\n")
print(nb2.kde.confmat$table)
colnames(df)
p5 <- ggplot(df, aes(x = Horizontal_Distance_To_Roadways, y = Elevation, color = Cover_Type))
p5 + geom_point()
colnames(df)
p5 <- ggplot(df, aes(x = Horizontal_Distance_To_Roadways, y = Horizontal_Distance_To_Fire_Points, color = Cover_Type))
p5 + geom_point()
?rpart
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(dplyr)
library(tidyr)
library(klaR)
library(matrixStats)
library(rpart)
library(ggplot2)
library(rpart.plot)
library(randomForest)
library(e1071)
library(class)
library(arules)
library(reshape2)
#Reading the data frame
df <- read.csv("train.csv")
#Creating a cos and sin of the
df <- df %>% mutate(sinAspect = sin(Aspect), cosAspect = cos(Aspect)) %>%
mutate(Euclidean_Distance_to_Hydrology =
sqrt(Vertical_Distance_To_Hydrology^2 + Horizontal_Distance_To_Hydrology^2))
#Deleting the id column
df <- df[, -1]
#Converting the cover tyoe into a factor
df$Cover_Type <- as.factor(df$Cover_Type)
#Looking for any missing columns
cat("Number of rows missing data:",sum(! complete.cases(df)), "\n")
set.seed(9999)
#Creating index for the cover type
train_ix <- createDataPartition(df$Cover_Type, p = 0.8, list = F)
#training set
train_df <- df[train_ix, ]
#test set
test_df <- df[-train_ix, ]
print("Training set dimensions:\n")
dim(train_df)
print("Test set dimensions:\n")
dim(test_df)
print("Distribution of Train Cover Types\n")
table(train_df$Cover_Type)
print("Distribution of Test Cover Types\n")
table(test_df$Cover_Type)
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(dplyr)
library(tidyr)
library(klaR)
library(matrixStats)
library(rpart)
library(ggplot2)
library(rpart.plot)
library(randomForest)
library(e1071)
library(class)
library(arules)
library(reshape2)
#Reading the data frame
df <- read.csv("train.csv")
#Creating a cos and sin of the
df <- df %>% mutate(sinAspect = sin(Aspect), cosAspect = cos(Aspect)) %>%
mutate(Euclidean_Distance_to_Hydrology =
sqrt(Vertical_Distance_To_Hydrology^2 + Horizontal_Distance_To_Hydrology^2))
#Deleting the id column
df <- df[, -1]
#Converting the cover tyoe into a factor
df$Cover_Type <- as.factor(df$Cover_Type)
#Looking for any missing columns
cat("Number of rows missing data:",sum(! complete.cases(df)), "\n")
set.seed(9999)
#Creating index for the cover type
train_ix <- createDataPartition(df$Cover_Type, p = 0.8, list = F)
#training set
train_df <- df[train_ix, ]
#test set
test_df <- df[-train_ix, ]
print("Training set dimensions:\n")
dim(train_df)
print("Test set dimensions:\n")
dim(test_df)
print("Distribution of Train Cover Types\n")
table(train_df$Cover_Type)
print("Distribution of Test Cover Types\n")
table(test_df$Cover_Type)
#How are the cover types distributed
wilderness <- df %>% dplyr::select(contains("Area"), contains("Cover"))
wilderness$Area <- ifelse(wilderness$Wilderness_Area1 == 1, "Area 1",
ifelse(wilderness$Wilderness_Area2 == 1, "Area 2",
ifelse(wilderness$Wilderness_Area3 == 1, "Area 3", "Area 4")))
wilderness <- wilderness[,c("Cover_Type", "Area")]
#plotting how the cover types are distributed by area
p1 <- ggplot(wilderness, aes(x = Area, fill = Cover_Type)) + geom_bar(color = "white")
p1 <- p1 + ggtitle("Cover Types in Each Area") + ylab("Number of Plots") + xlab("Wilderness Area")
print(p1)
print(table(wilderness$Cover_Type, wilderness$Area))
#train control
tc <- trainControl(method = "cv", number = 3)
#default decision tree
dt <- train(Cover_Type ~ ., data = train_df, trControl = tc, method = "rpart",
tuneGrid = expand.grid(cp = c(0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005)))
#looking at the the test set accuracy
preds <- predict(dt, test_df, "raw")
dt1.confmat <- confusionMatrix(preds, test_df$Cover_Type)
cat("Decision tree has an accuracy of", dt1.confmat$overall[1], "on hold out set\n\n")
dt1.confmat$table
dt$finalModel
dt$bestTune
dt
cat("Decision tree has an accuracy of", dt1.confmat$overall[1], "on hold out set\n\n")
dt1.confmat$table
#Random Forest
#training
rf <- train(Cover_Type ~ ., data = train_df, trControl = tc, method = "rf")
#cross-validation performance
#rf   #cross-validation accuracy of 0.837 with mtry = 29
#Accuracy on the hold out set
preds <- predict(rf$finalModel, test_df, "response")
rf.confmat <- confusionMatrix(preds, test_df$Cover_Type)
cat("Random Forest has an accuracy of", rf.confmat$overall[1], "on hold out set\n\n")
rf.confmat$table
varImp(rf)
#cross-validation performance
rf   #cross-validation accuracy of 0.837 with mtry = 29
cat("Random Forest has an accuracy of", rf.confmat$overall[1], "on hold out set\n\n")
rf.confmat$table
#Vector of continous variables
cont.cols <- c("Elevation", "Aspect", "Slope", "Horizontal_Distance_To_Hydrology", "Vertical_Distance_To_Hydrology", "Horizontal_Distance_To_Roadways", "Hillshade_9am", "Hillshade_Noon", "Hillshade_3pm", "Horizontal_Distance_To_Fire_Points", "sinAspect", "cosAspect", "Euclidean_Distance_to_Hydrology")
#training DF with all binary and scaled continous variables
train.scaled <- train_df %>% dplyr::select(one_of(cont.cols)) %>%
scale %>% cbind(train_df[,! colnames(train_df) %in% cont.cols])
#Scaled testdf
test.scaled <- test_df %>% dplyr::select(one_of(cont.cols)) %>%
scale(center = as.matrix(colMeans(train_df[,cont.cols])), scale = colSds(as.matrix(train_df[,cont.cols]))) %>%
cbind(test_df[,! colnames(test_df) %in% cont.cols])
#finding which kernel works best
#Linear
linear.grid = expand.grid(C = c(1, 0.9, 0.8, 0.5, 0.25, 0.1))
svm.linear <- train(Cover_Type ~ ., data = train.scaled, method = "svmLinear", trControl = tc, tuneGrid = linear.grid)
#svm.linear   #cv-3 Accuracy of 0.716
#Polynomial
poly.grid <- expand.grid(scale = c(0.1, 0.2), degree = c(3), C = c(1, 0.8))
svm.poly <- train(Cover_Type ~ ., data = train.scaled, method = "svmPoly", trControl = tc, tuneGrid = poly.grid)
#svm.poly   #cv-3 Accuracy of 0.782 scale - 0.2, C = 0.8
#Polynomial was better performing
svm.confmat <- confusionMatrix(predict(svm.poly, test.scaled), test.scaled$Cover_Type)
#Accuracy on hold out set
cat("SVM with Polynomial Kernel has an accuracy of", svm.confmat$overall[1], "on hold out set\n\n")
#Confusion matrix
print("SVM (Polynomial Kernel) Confusion Matrix\n")
print(svm.confmat$table)
svm.poly   #cv-3 Accuracy of 0.782 scale - 0.2, C = 0.8
#Accuracy on hold out set
cat("SVM with Polynomial Kernel has an accuracy of", svm.confmat$overall[1], "on hold out set\n\n")
print(svm.confmat$table)
varImp(rf)
#training the knn model
model_knn <- train(Cover_Type ~ ., data = train.scaled, method = "knn",
tuneGrid = data.frame(k = seq(1, 25)),
trControl = tc)
#predicting the test set
pred <- predict(model_knn, test.scaled)
#Confusion matrix
knn.confmat <- confusionMatrix(pred, test.scaled$Cover_Type)
cat("KNN w/ k = 1 has an accuracy of", knn.confmat$overall[1], "on hold out set\n\n")
knn.confmat$table
model_knn
cat("KNN w/ k = 1 has an accuracy of", knn.confmat$overall[1], "on hold out set\n\n")
knn.confmat$table
#Naive Bayes classifier
#getting names of all the categorical colnames
cat.cols <- train.scaled %>% dplyr::select(colnames(train_df[,! colnames(train_df) %in% cont.cols])) %>%
dplyr::select(-Cover_Type) %>% colnames
#Looping to discretize the categorical columns
train.nb <- train.scaled
for(col in cat.cols){
train.nb[,col] <- discretize(train.nb[,col], method = "fixed", breaks = c(-1,0.5,1.5), labels = c("NO", "YES"))
}
#Repeating above for test set
test.nb <- test.scaled
for(col in cat.cols){
test.nb[,col] <- discretize(test.nb[,col], method = "fixed", breaks = c(-1,0.5,1.5), labels = c("NO", "YES"))
}
#Naive Bayes LaPlace factor of 1, Normal Distribution
nb1 <- NaiveBayes(Cover_Type ~ ., data = train.nb, fL = 1)
preds <- suppressWarnings(predict(nb1, test.nb))
#Confusion Matrix for BB with laplace factor of 1
nb1.confmat <- confusionMatrix(preds$class, test.nb$Cover_Type)
cat("Naive Bayes w/ Normal Distribution and fL = 1 has an accuracy of", nb1.confmat$overall[1], "on hold out set\n\n")
print(nb1.confmat$table)
#Naive Bayes LaPlace factor of 1, KDE
nb.kde <- NaiveBayes(Cover_Type ~ ., data = train.nb, fL = 1, usekernel = T)
preds <- suppressWarnings(predict(nb.kde, test.nb))
#Confusion Matrix for BB with laplace factor of 1
nb.kde.confmat <- confusionMatrix(preds$class, test.nb$Cover_Type)
cat("Naive Bayes w/ KDE and fL = 1 has an accuracy of", nb.kde.confmat$overall[1], "on hold out set\n\n")
print(nb.kde.confmat$table)
#Naive Bayes LaPlace factor of 2, KDE
nb2.kde <- NaiveBayes(Cover_Type ~ ., data = train.nb, fL = 2, usekernel = T)
preds <- suppressWarnings(predict(nb2.kde, test.nb))
#Confusion Matrix for BB with laplace factor of 2
nb2.kde.confmat <- confusionMatrix(preds$class, test.nb$Cover_Type)
cat("Naive Bayes w/ KDE and fL = 2 has an accuracy of", nb2.kde.confmat$overall[1], "on hold out set\n\n")
print(nb2.kde.confmat$table)
#Naive Bayes LaPlace factor of 5, KDE
nb5.kde <- NaiveBayes(Cover_Type ~ ., data = train.nb, fL = 5, usekernel = T)
preds <- suppressWarnings(predict(nb5.kde, test.nb))
#Confusion Matrix for BB with laplace factor of 1
nb5.kde.confmat <- confusionMatrix(preds$class, test.nb$Cover_Type)
cat("Naive Bayes w/ KDE and fL = 5 has an accuracy of", nb5.kde.confmat$overall[1], "on hold out set\n\n")
print(nb5.kde.confmat$table)
print(nb.kde.confmat$table)
