print("Top words in Jay Cluster:")
km$centers[1, jay.top][1:5]
#looking at the kmeans clusters
p <- fviz_cluster(km, words[,3:ncol(words)])
p
word.dist <- words %>% select(c(-"author", -"filename", -"authorNum")) %>% dist
word.dist
word.dist <- words %>% select(c(-"author", -"filename", -"authorNum")) %>% dist(method = "euclidean")
#cutting the hierarchical cluster at k = 3
complete_hac <- cutree(hc, k = 3)
#distance of the scaled words
word.dist <- words %>% select(c(-"author", -"filename", -"authorNum")) %>% dist(method = "euclidean")
#hierarchical cluster of word distance
hc <- hclust(d = word.dist, method = "complete")
#cutting the hierarchical cluster at k = 3
complete_hac <- cutree(hc, k = 3)
#combining hierarchical cluster to actual id
complete_hac
#combining hierarchical cluster to actual id
complete_hac <- data.frame("Author" = words$authorNum, "cluster" = complete_hac)
#distance of the scaled words
word.dist <- words %>% select(c(-"author", -"filename", -"authorNum")) %>% dist(method = "euclidean")
#hierarchical cluster of word distance
hc <- hclust(d = word.dist, method = "complete")
#cutting the hierarchical cluster at k = 3
complete_hac <- cutree(hc, k = 3)
#combining hierarchical cluster to actual id
complete_hac <- data.frame("Author" = words$authorNum, "cluster" = complete_hac)
plot(jitter(complete_hac$cluster, 1) ~ complete_hac$authorNum, pch = 21,
col = as.factor(complete_hac$cluster), xlab = "Actual Author", ylab = "Cluster Number")
plot(jitter(complete_hac$cluster, 1) ~ complete_hac$Author, pch = 21,
col = as.factor(complete_hac$cluster), xlab = "Actual Author", ylab = "Cluster Number")
#distance of the scaled words
word.dist <- words %>% select(c(-"author", -"filename", -"authorNum")) %>% dist(method = "euclidean")
#hierarchical cluster of word distance
hc <- hclust(d = word.dist, method = "average")
#cutting the hierarchical cluster at k = 3
average_hac <- cutree(hc, k = 3)
#combining hierarchical cluster to actual id
average_hac <- data.frame("Author" = words$authorNum, "cluster" = average_hac)
plot(jitter(average_hac$cluster, 1) ~ average_hac$Author, pch = 21,
col = as.factor(complete_hac$cluster), xlab = "Actual Author", ylab = "Cluster Number")
#distance of the scaled words
word.dist <- words %>% select(c(-"author", -"filename", -"authorNum")) %>% dist(method = "euclidean")
#hierarchical cluster of word distance
hc <- hclust(d = word.dist, method = "average")
#cutting the hierarchical cluster at k = 3
average_hac <- cutree(hc, k = 3)
#combining hierarchical cluster to actual id
average_hac <- data.frame("Author" = words$authorNum, "cluster" = average_hac)
plot(average_hac$cluster ~ jitter(average_hac$Author, 1), pch = 21,
col = as.factor(complete_hac$cluster), xlab = "Actual Author", ylab = "Cluster Number")
plot(average_hac$cluster ~ jitter(average_hac$Author, 1), pch = 21,
col = as.factor(average_hac$cluster), xlab = "Actual Author", ylab = "Cluster Number")
#distance of the scaled words
word.dist <- words %>% select(c(-"author", -"filename", -"authorNum")) %>% dist(method = "euclidean")
#hierarchical cluster of word distance
hc <- hclust(d = word.dist, method = "single")
#cutting the hierarchical cluster at k = 3
single_hac <- cutree(hc, k = 3)
#combining hierarchical cluster to actual id
single_hac <- data.frame("Author" = words$authorNum, "cluster" = single_hac)
plot(single_hac$cluster ~ jitter(single_hac$Author, 1), pch = 21,
col = as.factor(single_hac$cluster), xlab = "Actual Author", ylab = "Cluster Number")
?hclust
#looking at the kmeans clusters
p <- fviz_cluster(km, words[,3:ncol(words)])
p
words$author == "HM"
words["author" == "HM", ]
words[words$author == "HM", ]
#looking at the kmeans clusters
p <- fviz_cluster(km, words[,3:ncol(words)])
p
print(p)
p$data
p$data[63:35]
p$data[63:35, ]
p$data[63:65, ]
words$author == "HM"
?geom_point
#looking at the kmeans clusters
p <- fviz_cluster(km, words[,3:ncol(words)])
p <- p + geom_point(aes(x = p$data[63:65, "x"], y = p$data[63:65, "y"]), shape = "ro")
print(p)
p$data[63:65, "x"]
#looking at the kmeans clusters
p <- fviz_cluster(km, words[,3:ncol(words)])
p <- p + geom_point(aes(x = p$data[63:65, "x"], y = p$data[63:65, "y"]))
print(p)
#looking at the kmeans clusters
p <- fviz_cluster(km, words[,3:ncol(words)])
print(p)
#Top words for Hamilton Cluster
hamilton.top <- order(abs(km$centers[2, ]), decreasing = T)
print("Top words in Hamilton Cluster:")
print(km$centers[2, hamilton.top][1:5])
#Top words by Madison
madison.top <- order(abs(km$centers[3, ]), decreasing = T)
print("Top words in Madison Cluster:")
print(km$centers[3, madison.top][1:5])
#Top Words in papers by Jay
jay.top <- order(abs(km$centers[1, ]), decreasing = T)
print("Top words in Jay Cluster:")
km$centers[1, jay.top][1:5]
#looking at the kmeans clusters
p <- fviz_cluster(km, words[,3:ncol(words)])
print(p)
#distance of the scaled words
word.dist <- words %>% select(c(-"author", -"filename", -"authorNum")) %>% dist(method = "euclidean")
#hierarchical cluster of word distance
hc <- hclust(d = word.dist, method = "single")
#cutting the hierarchical cluster at k = 3
single_hac <- cutree(hc, k = 3)
#combining hierarchical cluster to actual id
single_hac <- data.frame("Author" = words$authorNum, "cluster" = single_hac)
plot(single_hac$cluster ~ jitter(single_hac$Author, 1), pch = 21,
col = as.factor(single_hac$cluster), xlab = "Actual Author", ylab = "Cluster Number")
library(EMCluster)
knitr::opts_chunk$set(echo = TRUE)
library(factoextra)
library(dplyr)
library(tidyr)
#Reading the frequencies for the words
words <- read.csv("fedPapers85.csv")
#Scaling the words
words[,3:ncol(words)] <- scale(words[, 3:ncol(words)])
set.seed(1000)
#Creating kmeans model
km <- kmeans(words[,3:ncol(words)], centers = 3, iter.max = 100, nstart = 100)
#Adding the cluster to the data frame
words$cluster <- km$cluster
#plotting the clusters
words$authorNum <- ifelse(words$author == "Hamilton", 0,
ifelse(words$author == "HM", 1, ifelse(words$author == "dispt", 2,
ifelse(words$author == "Madison", 3, 4))))
#plotting the success of cluster
p <- plot(jitter(words$cluster, 1) ~ words$authorNum, pch = 21, col = as.factor(words$cluster),
xlab = "Actual Author", ylab = "Cluster Number")
library(factoextra)
library(dplyr)
library(tidyr)
#Reading the frequencies for the words
words <- read.csv("fedPapers85.csv")
#Scaling the words
words[,3:ncol(words)] <- scale(words[, 3:ncol(words)])
set.seed(1000)
#Creating kmeans model
km <- kmeans(words[,3:ncol(words)], centers = 3, iter.max = 100, nstart = 100)
#Adding the cluster to the data frame
words$cluster <- km$cluster
#plotting the clusters
words$authorNum <- ifelse(words$author == "Hamilton", 0,
ifelse(words$author == "HM", 1, ifelse(words$author == "dispt", 2,
ifelse(words$author == "Madison", 3, 4))))
#plotting the success of cluster
p <- plot(jitter(words$cluster, 1) ~ words$authorNum, pch = 21, col = as.factor(words$cluster),
xlab = "Actual Author", ylab = "Cluster Number")
table(words$author, words$cluster)
#table of the clusters vs
table(words$cluster, words$author)
#distance of words
word.dist <- dist(words[,3:ncol(words)], method = "euclidean")
#distance of the scaled words
#word.dist <- words %>% select(c(-"author", -"filename", -"authorNum")) %>% dist(method = "euclidean")
#Reading the frequencies for the words
words <- read.csv("fedPapers85.csv")
#distance of words
word.dist <- dist(words[,3:ncol(words)], method = "euclidean")
#hierarchical cluster of word distance
hc <- hclust(d = word.dist, method = "complete")
#cutting the hierarchical cluster at k = 3
complete_hac <- cutree(hc, k = 3)
#combining hierarchical cluster to actual id
complete_hac <- data.frame("Author" = words$authorNum, "cluster" = complete_hac)
#distance of the scaled words
#word.dist <- words %>% select(c(-"author", -"filename", -"authorNum")) %>% dist(method = "euclidean")
#Reading the frequencies for the words
words <- read.csv("fedPapers85.csv")
#distance of the scaled words
#word.dist <- words %>% select(c(-"author", -"filename", -"authorNum")) %>% dist(method = "euclidean")
#Reading the frequencies for the words
words <- read.csv("fedPapers85.csv")
#distance of words
word.dist <- dist(words[,3:ncol(words)], method = "euclidean")
#Adding Author num
words$authorNum <- ifelse(words$author == "Hamilton", 0,
ifelse(words$author == "HM", 1, ifelse(words$author == "dispt", 2,
ifelse(words$author == "Madison", 3, 4))))
#hierarchical cluster of word distance
hc <- hclust(d = word.dist, method = "complete")
#cutting the hierarchical cluster at k = 3
complete_hac <- cutree(hc, k = 3)
#combining hierarchical cluster to actual id
complete_hac <- data.frame("Author" = words$authorNum, "cluster" = complete_hac)
plot(jitter(complete_hac$cluster, 1) ~ complete_hac$Author, pch = 21,
col = as.factor(complete_hac$cluster), xlab = "Actual Author", ylab = "Cluster Number")
library(factoextra)
library(dplyr)
library(tidyr)
#Reading the frequencies for the words
words <- read.csv("fedPapers85.csv")
#Scaling the words
words[,3:ncol(words)] <- scale(words[, 3:ncol(words)])
set.seed(1000)
#Creating kmeans model
km <- kmeans(words[,3:ncol(words)], centers = 3, iter.max = 100, nstart = 100)
#Adding the cluster to the data frame
words$cluster <- km$cluster
#plotting the clusters
words$authorNum <- ifelse(words$author == "Hamilton", 0,
ifelse(words$author == "HM", 1, ifelse(words$author == "dispt", 2,
ifelse(words$author == "Madison", 3, 4))))
#plotting the success of cluster
p <- plot(jitter(words$cluster, 1) ~ words$authorNum, pch = 21, col = as.factor(words$cluster),
xlab = "Actual Author", ylab = "Cluster Number")
#table of the clusters vs
table(words$cluster, words$author)
#Top words for Hamilton Cluster
hamilton.top <- order(km$centers[2, ], decreasing = T)
print("Top words in Hamilton Cluster:")
print(km$centers[2, hamilton.top][1:5])
#Top words by Madison
madison.top <- order(km$centers[3, ], decreasing = T)
print("Top words in Madison Cluster:")
print(km$centers[3, madison.top][1:5])
#Top Words in papers by Jay
jay.top <- order(km$centers[1, ], decreasing = T)
print("Top words in Jay Cluster:")
km$centers[1, jay.top][1:5]
#looking at the kmeans clusters
p <- fviz_cluster(km, words[,3:ncol(words)])
print(p)
#distance of the scaled words
word.dist <- words %>% select(c(-"author", -"filename", -"authorNum")) %>% dist(method = "euclidean")
#Reading the frequencies for the words
#hierarchical cluster of word distance
hc <- hclust(d = word.dist, method = "complete")
#cutting the hierarchical cluster at k = 3
complete_hac <- cutree(hc, k = 3)
#combining hierarchical cluster to actual id
complete_hac <- data.frame("Author" = words$authorNum, "cluster" = complete_hac)
plot(jitter(complete_hac$cluster, 1) ~ complete_hac$Author, pch = 21,
col = as.factor(complete_hac$cluster), xlab = "Actual Author", ylab = "Cluster Number")
#Reading the frequencies for the words
words <- read.csv("fedPapers85.csv")
#distance of words
word.dist <- dist(words[,3:ncol(words)], method = "euclidean")
#Adding Author num
words$authorNum <- ifelse(words$author == "Hamilton", 0,
ifelse(words$author == "HM", 1, ifelse(words$author == "dispt", 2,
ifelse(words$author == "Madison", 3, 4))))
#hierarchical cluster of word distance
hc <- hclust(d = word.dist, method = "complete")
#cutting the hierarchical cluster at k = 3
complete_hac <- cutree(hc, k = 3)
#combining hierarchical cluster to actual id
complete_hac <- data.frame("Author" = words$authorNum, "cluster" = complete_hac)
plot(jitter(complete_hac$cluster, 1) ~ complete_hac$Author, pch = 21,
col = as.factor(complete_hac$cluster), xlab = "Actual Author", ylab = "Cluster Number")
library(factoextra)
library(dplyr)
library(tidyr)
#Reading the frequencies for the words
words <- read.csv("fedPapers85.csv")
#Scaling the words
words[,3:ncol(words)] <- scale(words[, 3:ncol(words)])
set.seed(1000)
#Creating kmeans model
km <- kmeans(words[,3:ncol(words)], centers = 3, iter.max = 100, nstart = 100)
#Adding the cluster to the data frame
words$cluster <- km$cluster
#plotting the clusters
words$authorNum <- ifelse(words$author == "Hamilton", 0,
ifelse(words$author == "HM", 1, ifelse(words$author == "dispt", 2,
ifelse(words$author == "Madison", 3, 4))))
#plotting the success of cluster
p <- plot(jitter(words$cluster, 1) ~ words$authorNum, pch = 21, col = as.factor(words$cluster),
xlab = "Actual Author", ylab = "Cluster Number")
#table of the clusters vs
table(words$cluster, words$author)
#table of the clusters vs
table(words$cluster, words$author)
#Top words for Hamilton Cluster
hamilton.top <- order(km$centers[2, ], decreasing = T)
print("Top words in Hamilton Cluster:")
print(km$centers[2, hamilton.top][1:5])
#Top words by Madison
madison.top <- order(km$centers[3, ], decreasing = T)
print("Top words in Madison Cluster:")
print(km$centers[3, madison.top][1:5])
#Top Words in papers by Jay
jay.top <- order(km$centers[1, ], decreasing = T)
print("Top words in Jay Cluster:")
km$centers[1, jay.top][1:5]
library(factoextra)
library(dplyr)
library(tidyr)
#Reading the frequencies for the words
words <- read.csv("fedPapers85.csv")
#Scaling the words
words[,3:ncol(words)] <- scale(words[, 3:ncol(words)])
words
View(words)
#distance of the scaled words
word.dist <- words %>% select(c(-"author", -"filename", -"authorNum")) %>% dist(method = "euclidean")
library(factoextra)
library(dplyr)
library(tidyr)
#Reading the frequencies for the words
words <- read.csv("fedPapers85.csv")
#Scaling the words
words[,3:ncol(words)] <- scale(words[, 3:ncol(words)])
set.seed(1000)
#Creating kmeans model
km <- kmeans(words[,3:ncol(words)], centers = 3, iter.max = 100, nstart = 100)
#Adding the cluster to the data frame
words$cluster <- km$cluster
#plotting the clusters
words$authorNum <- ifelse(words$author == "Hamilton", 0,
ifelse(words$author == "HM", 1, ifelse(words$author == "dispt", 2,
ifelse(words$author == "Madison", 3, 4))))
#plotting the success of cluster
p <- plot(jitter(words$cluster, 1) ~ words$authorNum, pch = 21, col = as.factor(words$cluster),
xlab = "Actual Author", ylab = "Cluster Number")
#table of the clusters vs
table(words$cluster, words$author)
#Top words for Hamilton Cluster
hamilton.top <- order(km$centers[2, ], decreasing = T)
print("Top words in Hamilton Cluster:")
print(km$centers[2, hamilton.top][1:5])
#Top words by Madison
madison.top <- order(km$centers[3, ], decreasing = T)
print("Top words in Madison Cluster:")
print(km$centers[3, madison.top][1:5])
#Top Words in papers by Jay
jay.top <- order(km$centers[1, ], decreasing = T)
print("Top words in Jay Cluster:")
km$centers[1, jay.top][1:5]
#looking at the kmeans clusters
p <- fviz_cluster(km, words[,3:ncol(words)])
print(p)
#distance of the scaled words
word.dist <- words %>% select(c(-"author", -"filename", -"authorNum")) %>% dist(method = "euclidean")
#hierarchical cluster of word distance
hc <- hclust(d = word.dist, method = "complete")
#cutting the hierarchical cluster at k = 3
complete_hac <- cutree(hc, k = 3)
#combining hierarchical cluster to actual id
complete_hac <- data.frame("Author" = words$authorNum, "cluster" = complete_hac)
plot(complete_hac$cluster ~ jitter(complete_hac$Author, 1), pch = 21,
col = as.factor(complete_hac$cluster), xlab = "Actual Author", ylab = "Cluster Number")
#distance of the scaled words
word.dist <- words %>% select(c(-"author", -"filename", -"authorNum")) %>% dist(method = "euclidean")
#hierarchical cluster of word distance
hc <- hclust(d = word.dist, method = "average")
#cutting the hierarchical cluster at k = 3
average_hac <- cutree(hc, k = 3)
#combining hierarchical cluster to actual id
average_hac <- data.frame("Author" = words$authorNum, "cluster" = average_hac)
plot(average_hac$cluster ~ jitter(average_hac$Author, 1), pch = 21,
col = as.factor(average_hac$cluster), xlab = "Actual Author", ylab = "Cluster Number")
#distance of the scaled words
word.dist <- words %>% select(c(-"author", -"filename", -"authorNum")) %>% dist(method = "euclidean")
#hierarchical cluster of word distance
hc <- hclust(d = word.dist, method = "single")
#cutting the hierarchical cluster at k = 3
single_hac <- cutree(hc, k = 3)
#combining hierarchical cluster to actual id
single_hac <- data.frame("Author" = words$authorNum, "cluster" = single_hac)
plot(single_hac$cluster ~ jitter(single_hac$Author, 1), pch = 21,
col = as.factor(single_hac$cluster), xlab = "Actual Author", ylab = "Cluster Number")
#heatmap of distance
fviz_dist(word.dist)
#heatmap of distance
fviz_dist(word.dist, show_labels = T)
#heatmap of distance
fviz_dist(word.dist, show_labels = F)
?kmeans
knitr::opts_chunk$set(echo = TRUE)
library(factoextra)
library(dplyr)
library(tidyr)
#Reading the frequencies for the words
words <- read.csv("fedPapers85.csv")
#Scaling the words
words[,3:ncol(words)] <- scale(words[, 3:ncol(words)])
set.seed(1000)
#Creating kmeans model
km <- kmeans(words[,3:ncol(words)], centers = 3, iter.max = 100, nstart = 100)
#Adding the cluster to the data frame
words$cluster <- km$cluster
#plotting the clusters
words$authorNum <- ifelse(words$author == "Hamilton", 0,
ifelse(words$author == "HM", 1, ifelse(words$author == "dispt", 2,
ifelse(words$author == "Madison", 3, 4))))
#plotting the success of cluster
plot(jitter(words$cluster, 1) ~ words$authorNum, pch = 21, col = as.factor(words$cluster),
xlab = "Actual Author", ylab = "Cluster Number")
print(words %>% filter(author == "dispt") %>%
select(c("filename", "cluster")))
#table of the clusters vs
auth.table <- table(words$cluster[words$author %in%  c("Hamilton","Jay","Madison")],
words$author[words$author %in%  c("Hamilton","Jay","Madison")])
km.known.table <- auth.table[,c("Jay", "Hamilton", "Madison")]
km.acc <- sum(diag(known.table)) / sum(known.table) * 100
#table of the clusters vs
auth.table <- table(words$cluster[words$author %in%  c("Hamilton","Jay","Madison")],
words$author[words$author %in%  c("Hamilton","Jay","Madison")])
km.known.table <- auth.table[,c("Jay", "Hamilton", "Madison")]
km.acc <- sum(diag(km.known.table)) / sum(known.table) * 100
#table of the clusters vs
auth.table <- table(words$cluster[words$author %in%  c("Hamilton","Jay","Madison")],
words$author[words$author %in%  c("Hamilton","Jay","Madison")])
km.known.table <- auth.table[,c("Jay", "Hamilton", "Madison")]
km.acc <- sum(diag(km.known.table)) / sum(km.known.table) * 100
cat("Accuracy of KM on known documents: ", round(km.acc, 2), "%", sep = "")
knitr::kable(km.known.table)
#Top Words in papers by Jay
jay.top <- order(km$centers[1, ], decreasing = T)
print("Top words in Jay Cluster:")
print(km$centers[1, jay.top][1:5])
#Top words for Hamilton Cluster
hamilton.top <- order(km$centers[2, ], decreasing = T)
print("Top words in Hamilton Cluster:")
print(km$centers[2, hamilton.top][1:5])
#Top words by Madison
madison.top <- order(km$centers[3, ], decreasing = T)
print("Top words in Madison Cluster:")
print(km$centers[3, madison.top][1:5])
#Bottom Words in papers by Jay
jay.bottom <- order(km$centers[1, ])
print("Least Frequently use words in Jay Cluster:")
print(km$centers[1, jay.bottom][1:5])
#Bottom Words in papers by Hamilton
hamilton.bottom <- order(km$centers[2, ])
print("Least Frequently use words in Hamilton Cluster:")
print(km$centers[2, hamilton.bottom][1:5])
#Bottom Words in papers by Hamilton
madison.bottom <- order(km$centers[3, ])
print("Least Frequently use words in Madison Cluster:")
print(km$centers[3, madison.bottom][1:5])
#Jay important words
print("Most important Jay words")
jay.important <- order(abs(km$centers[1,]), decreasing = T)
print(km$centers[1, jay.important[1:3]])
#Hamilton important words
print("Most important Hamilton words")
hamilton.important <- order(abs(km$centers[2,]), decreasing = T)
print(km$centers[2, hamilton.important[1:3]])
#Madison important words
print("Most important Hamilton words")
madison.important <- order(abs(km$centers[3,]), decreasing = T)
print(km$centers[3, madison.important[1:3]])
#looking at the kmeans clusters
p <- fviz_cluster(km, words[,3:ncol(words)])
print(p)
?fviz_cluster
#looking at the kmeans clusters
p <- fviz_cluster(km, words[,3:ncol(words)])
print(p)
print(km$withinss)
print(km$totss)
print(km$betweenss)
print(km$withinss)
#looking at the kmeans clusters
p <- fviz_cluster(km, words[,3:ncol(words)])
print(p)
?sse
?km
?kmeans
?hclust
plot(hc)
#hierarchical cluster of word distance
hc <- hclust(d = word.dist, method = "complete")
#distance of the scaled words
word.dist <- words %>% select(c(-"author", -"filename", -"authorNum")) %>% dist(method = "euclidean")
#heatmap of distance
fviz_dist(word.dist, show_labels = F)
#hierarchical cluster of word distance
hc <- hclust(d = word.dist, method = "complete")
#cutting the hierarchical cluster at k = 3
complete_hac <- cutree(hc, k = 3)
#combining hierarchical cluster to actual id
complete_hac <- data.frame("Author" = words$authorNum, "cluster" = complete_hac)
plot(complete_hac$cluster ~ jitter(complete_hac$Author, 1), pch = 21,
col = as.factor(complete_hac$cluster), xlab = "Actual Author", ylab = "Cluster Number")
plot(hc)
plot(hc)
#distance of the scaled words
word.dist <- words %>% select(c(-"author", -"filename", -"authorNum")) %>% dist(method = "euclidean")
#hierarchical cluster of word distance
hc <- hclust(d = word.dist, method = "average")
#cutting the hierarchical cluster at k = 3
average_hac <- cutree(hc, k = 3)
#combining hierarchical cluster to actual id
average_hac <- data.frame("Author" = words$authorNum, "cluster" = average_hac)
plot(average_hac$cluster ~ jitter(average_hac$Author, 1), pch = 21,
col = as.factor(average_hac$cluster), xlab = "Actual Author", ylab = "Cluster Number")
plot(hc)
plot(hc)
#distance of the scaled words
word.dist <- words %>% select(c(-"author", -"filename", -"authorNum")) %>% dist(method = "euclidean")
#hierarchical cluster of word distance
hc <- hclust(d = word.dist, method = "single")
#cutting the hierarchical cluster at k = 3
single_hac <- cutree(hc, k = 3)
#combining hierarchical cluster to actual id
single_hac <- data.frame("Author" = words$authorNum, "cluster" = single_hac)
plot(single_hac$cluster ~ jitter(single_hac$Author, 1), pch = 21,
col = as.factor(single_hac$cluster), xlab = "Actual Author", ylab = "Cluster Number")
plot(hc)
