id <- seq_along(reviews)
#Creating the data frame
df <- data.frame(id = id, sentiment = sentiment, lie = lies, review = reviews)
#Getting rid of the first row
df <- df[2:nrow(df), ]
#Converting id to character
df$review <- as.character(df$review)
#tokenizing
review_words <- df %>%
select(id, sentiment, lie, review) %>%
unnest_tokens(word, review, to_lower = TRUE)
#stemming
review_words$word <- wordStem(review_words$word)
#removing non-alphabetical tokens
review_words <- review_words %>%
filter(str_detect(word, "^[a-z']+$"))
#Making tfidf
review_words_dtm <- review_words %>%
count(id, sentiment, lie, word) %>%
bind_tf_idf(word, id, n) %>%
select(id, sentiment, lie, word, tf_idf) %>%
spread(key = word, value = tf_idf)
knitr::opts_chunk$set(echo = TRUE)
library(tidytext)
library(stringr)
library(dplyr)
library(tidyr)
library(wordcloud)
library(ggplot2)
library(SnowballC)
library(caret)
library(e1071)
#Reading the data
data <- readLines("lie_detector.csv")
#empty vectors of data
lies <- character(length = length(data))
sentiment <- character(length = length(data))
reviews <- character(length = length(data))
#looping through the lines
for (i in seq_along(data)){
#getting the line
line <- data[i]
#Getting the lie
lies[i] <- substr(line, 1, 1)
#Gettinf the sentiment
sentiment[i] <- substr(line, 3, 3)
#getting the review
review <- substr(line, 6, (nchar(line) - 1))
#Replacing the backslashes
review <- gsub("\\", "", review, fixed = T)
#saving the reviews
reviews[i] <- review
}
#Creating IDs for the reviews
id <- seq_along(reviews)
#Creating the data frame
df <- data.frame(id = id, sentiment = sentiment, lie = lies, review = reviews)
#Getting rid of the first row
df <- df[2:nrow(df), ]
#Converting id to character
df$review <- as.character(df$review)
#tokenizing
review_words <- df %>%
select(id, sentiment, lie, review) %>%
unnest_tokens(word, review, to_lower = TRUE)
#stemming
review_words$word <- wordStem(review_words$word)
#removing non-alphabetical tokens
review_words <- review_words %>%
filter(str_detect(word, "^[a-z']+$"))
#Making tfidf
review_words_dtm <- review_words %>%
count(id, sentiment, lie, word) %>%
bind_tf_idf(word, id, n) %>%
select(id, sentiment, lie, word, tf_idf) %>%
spread(key = word, value = tf_idf)
#Making a data frame for only sentiment analysis
sentiment_df <- review_words_dtm %>%
select(-id, -lie)
#Replacing na with 0
sentiment_df[is.na(sentiment_df)] <- 0
#train control
tc <- trainControl(method = "cv", number = 5)
#SVM cost grid
linear.grid = expand.grid(C = c(1, 0.9, 0.8, 0.5, 0.25, 0.1))
#training svm
svm <- train(sentiment ~ ., data = sentiment_df, trControl = tc, method = "svmLinear", tuneGrid = linear.grid)
sentiment_df$sentiment <- droplevels(sentiment_df$sentiment)
#training svm
svm <- train(sentiment ~ ., data = sentiment_df, trControl = tc, method = "svmLinear", tuneGrid = linear.grid)
svm
library(klaR)
?naiveBayes
?NaiveBayes
nb.grid = expand.grid(usekernel = c(T, F), fL = c(1, 3, 5, 9, 20))
nb.grid = expand.grid(usekernel = c(T, F), fL = c(1, 3, 5, 9, 20), adjust = 0)
#training svm
nb.sentiment <- train(sentiment ~ ., data = sentiment_df, trControl = tc, method = "nb", tuneGrid = linear.grid)
#training svm
nb.sentiment <- train(sentiment ~ ., data = sentiment_df, trControl = tc, method = "nb", tuneGrid = nb.grid)
nb.grid = expand.grid(usekernel = c(T), fL = c(1, 3, 5, 9, 20), adjust = 0)
#training svm
nb.sentiment <- train(sentiment ~ ., data = sentiment_df, trControl = tc, method = "nb", tuneGrid = nb.grid)
#training svm
nb.sentiment <- NaiveBayes(sentiment ~ ., data = sentiment_df, usekernel = T, fL = 1)
nb.sentiment
nb.sentiment.confmat <- confusionMatrix(predict(nb.sentiment(sentiment_df)), sentiment_df$sentiment)
nb.sentiment.confmat <- confusionMatrix(predict(nb.sentiment(sentiment_df)), sentiment_df$sentiment)
#training svm
nb1.sentiment <- NaiveBayes(sentiment ~ ., data = sentiment_df, usekernel = T, fL = 1)
preds <- predict(nb1.sentiment, sentiment_df)
preds <- predict(nb1.sentiment, sentiment_df %>% select(-sentiment))
preds <- predict(nb1.sentiment, sentiment_df)
#training svm
nb1.sentiment <- NaiveBayes(sentiment ~ ., data = sentiment_df, usekernel = F, fL = 1)
#training svm
nb1.sentiment <- NaiveBayes(sentiment ~ ., data = sentiment_df, usekernel = T, fL = 1)
?predict
predict(object = nb1.sentiment, sentiment_df)
temp <- sentiment_df %>% select(-sentiment)
temp <- sentiment_df %>% select(-sentiment)
temp <- sentiment_df %>% dplyr::select(-sentiment)
knitr::opts_chunk$set(echo = TRUE)
library(tidytext)
library(stringr)
library(dplyr)
library(tidyr)
library(wordcloud)
library(ggplot2)
library(SnowballC)
library(caret)
library(e1071)
library(klaR)
#Reading the data
data <- readLines("lie_detector.csv")
#empty vectors of data
lies <- character(length = length(data))
sentiment <- character(length = length(data))
reviews <- character(length = length(data))
#looping through the lines
for (i in seq_along(data)){
#getting the line
line <- data[i]
#Getting the lie
lies[i] <- substr(line, 1, 1)
#Gettinf the sentiment
sentiment[i] <- substr(line, 3, 3)
#getting the review
review <- substr(line, 6, (nchar(line) - 1))
#Replacing the backslashes
review <- gsub("\\", "", review, fixed = T)
#saving the reviews
reviews[i] <- review
}
#Creating IDs for the reviews
id <- seq_along(reviews)
#Creating the data frame
df <- data.frame(id = id, sentiment = sentiment, lie = lies, review = reviews)
#Getting rid of the first row
df <- df[2:nrow(df), ]
#Converting id to character
df$review <- as.character(df$review)
#tokenizing
review_words <- df %>%
dplyr::select(id, sentiment, lie, review) %>%
unnest_tokens(word, review, to_lower = TRUE)
#stemming
review_words$word <- wordStem(review_words$word)
#removing non-alphabetical tokens
review_words <- review_words %>%
filter(str_detect(word, "^[a-z']+$"))
#Making tfidf
review_words_dtm <- review_words %>%
count(id, sentiment, lie, word) %>%
bind_tf_idf(word, id, n) %>%
dplyr::select(id, sentiment, lie, word, tf_idf) %>%
spread(key = word, value = tf_idf)
#Making a data frame for only sentiment analysis
sentiment_df <- review_words_dtm %>%
dplyr::select(-id, -lie)
sentiment_df$sentiment <- droplevels(sentiment_df$sentiment)
#Replacing na with 0
sentiment_df[is.na(sentiment_df)] <- 0
#train test split
set.seed(9999)
train_ix <- createDataPartition(sentiment_df$sentiment, p = 0.75, list = F)
sentiment.train <- sentiment_df[train_ix, ]
sentiment.test <- sentiment_df[-train_ix, ]
#train control
tc <- trainControl(method = "cv", number = 5)
#SVM cost grid
linear.grid = expand.grid(C = c(1, 0.9, 0.8, 0.5, 0.25, 0.1))
#training svm
svm.sentiment <- suppressWarnings(train(sentiment ~ ., data = sentiment.train, trControl = tc,
method = "svmLinear", tuneGrid = linear.grid))
preds <- predict(svm.sentiment, sentiment.test)
confusionMatrix(preds, sentiment.test$sentiment)
table(sentiment.train$sentiment)
svm.sentiment
#training svm
svm.sentiment <- suppressWarnings(train(sentiment ~ ., data = sentiment.train, trControl = tc,
method = "svmPoly", tuneGrid = linear.grid))
#training svm
svm.sentiment <- suppressWarnings(train(sentiment ~ ., data = sentiment.train, trControl = tc,
method = "svmPoly"))
svm.sentiment
head(sentiment_df)
#Reading the data
data <- readLines("lie_detector.csv")
#empty vectors of data
lies <- character(length = length(data))
sentiment <- character(length = length(data))
reviews <- character(length = length(data))
#looping through the lines
for (i in seq_along(data)){
#getting the line
line <- data[i]
#Getting the lie
lies[i] <- substr(line, 1, 1)
#Gettinf the sentiment
sentiment[i] <- substr(line, 3, 3)
#getting the review
review <- substr(line, 6, (nchar(line) - 1))
#Replacing the backslashes
review <- gsub("\\", "", review, fixed = T)
#saving the reviews
reviews[i] <- review
}
#Creating IDs for the reviews
id <- seq_along(reviews)
#Creating the data frame
df <- data.frame(id = id, sentiment = sentiment, lie = lies, review = reviews)
#Getting rid of the first row
df <- df[2:nrow(df), ]
#Converting id to character
df$review <- as.character(df$review)
#tokenizing
review_words <- df %>%
dplyr::select(id, sentiment, lie, review) %>%
unnest_tokens(word, review, to_lower = TRUE)
#stemming
review_words$word <- wordStem(review_words$word)
#removing non-alphabetical tokens
review_words <- review_words %>%
filter(!word %in% stop_words$word,
str_detect(word, "^[a-z']+$"))
#Making tfidf
review_words_dtm <- review_words %>%
count(id, sentiment, lie, word) %>%
bind_tf_idf(word, id, n) %>%
dplyr::select(id, sentiment, lie, word, tf_idf) %>%
spread(key = word, value = tf_idf)
#Reading the data
data <- readLines("lie_detector.csv")
#empty vectors of data
lies <- character(length = length(data))
sentiment <- character(length = length(data))
reviews <- character(length = length(data))
#looping through the lines
for (i in seq_along(data)){
#getting the line
line <- data[i]
#Getting the lie
lies[i] <- substr(line, 1, 1)
#Gettinf the sentiment
sentiment[i] <- substr(line, 3, 3)
#getting the review
review <- substr(line, 6, (nchar(line) - 1))
#Replacing the backslashes
review <- gsub("\\", "", review, fixed = T)
#saving the reviews
reviews[i] <- review
}
#Creating IDs for the reviews
id <- seq_along(reviews)
#Creating the data frame
df <- data.frame(id = id, sentiment = sentiment, lie = lies, review = reviews)
#Getting rid of the first row
df <- df[2:nrow(df), ]
#Converting id to character
df$review <- as.character(df$review)
#tokenizing
review_words <- df %>%
dplyr::select(id, sentiment, lie, review) %>%
unnest_tokens(word, review, to_lower = TRUE)
#stemming
review_words$word <- wordStem(review_words$word)
#removing non-alphabetical tokens
review_words <- review_words %>%
filter(!word %in% stop_words$word,
str_detect(word, "^[a-z']+$"))
#Making tfidf
review_words_dtm <- review_words %>%
count(id, sentiment, lie, word) %>%
bind_tf_idf(word, id, n) %>%
dplyr::select(id, sentiment, lie, word, tf_idf) %>%
spread(key = word, value = tf_idf)
#Making a data frame for only sentiment analysis
sentiment_df <- review_words_dtm %>%
dplyr::select(-id, -lie)
sentiment_df$sentiment <- droplevels(sentiment_df$sentiment)
#Replacing na with 0
sentiment_df[is.na(sentiment_df)] <- 0
#train test split
set.seed(9999)
train_ix <- createDataPartition(sentiment_df$sentiment, p = 0.75, list = F)
sentiment.train <- sentiment_df[train_ix, ]
#train control
tc <- trainControl(method = "cv", number = 5)
#SVM cost grid
linear.grid = expand.grid(C = c(1, 0.9, 0.8, 0.5, 0.25, 0.1))
#training svm
svm.sentiment <- suppressWarnings(train(sentiment ~ ., data = sentiment.train, trControl = tc,
method = "svmLinear", tuneGrid = linear.grid))
svm.sentiment
preds <- predict(svm.sentiment, sentiment.test)
confusionMatrix(preds, sentiment.test$sentiment)
#training svm
nb1.sentiment <- NaiveBayes(sentiment ~ ., data = sentiment_df, usekernel = T, fL = 1)
predict(nb1.sentiment, sentiment_df)
#training svm
nb1.sentiment <- NaiveBayes(sentiment ~ ., data = sentiment.train, usekernel = T, fL = 1)
predict(nb1.sentiment, sentiment.test)
sentiment.train <- sentiment_df[train_ix, ]
sentiment.test <- sentiment_df[-train_ix, ]
#train control
tc <- trainControl(method = "cv", number = 5)
#SVM cost grid
linear.grid = expand.grid(C = c(1, 0.9, 0.8, 0.5, 0.25, 0.1))
#training svm
svm.sentiment <- suppressWarnings(train(sentiment ~ ., data = sentiment.train, trControl = tc,
method = "svmLinear", tuneGrid = linear.grid))
preds <- predict(svm.sentiment, sentiment.test)
svm.confmat <- confusionMatrix(preds, sentiment.test$sentiment)
svm.confmat$overall[1]
svm.confmat$table
#training svm
nb1.sentiment <- NaiveBayes(sentiment ~ ., data = sentiment.train, usekernel = T, fL = 1)
predict(nb1.sentiment, sentiment.test)
#training svm
nb1.sentiment <- NaiveBayes(sentiment ~ ., data = sentiment_df, usekernel = T, fL = 1)
predict(nb1.sentiment, sentiment_df)
nb1.sentiment
length(nb1.sentiment$tables)
temp.sentiment <- sentiment_df %>% dplyr::select(-sentiment)
predict(nb1.sentiment, temp.sentiment)
#training svm
nb1.sentiment <- NaiveBayes(sentiment ~ ., data = sentiment_df, usekernel = T, fL = 1)
#training svm
nb1.sentiment <- NaiveBayes(sentiment ~ ., data = sentiment_df, usekernel = T, fL = 1)
temp.sentiment <- sentiment_df %>% dplyr::select(-sentiment)
predict(nb1.sentiment, temp.sentiment, "class")
#training svm
nb1.sentiment <- NaiveBayes(sentiment ~ ., data = sentiment_df, usekernel = T, fL = 1)
temp.sentiment <- sentiment_df %>% dplyr::select(-sentiment)
predict(nb1.sentiment, temp.sentiment, "class")
knitr::opts_chunk$set(echo = TRUE)
library(tidytext)
library(stringr)
library(dplyr)
library(tidyr)
library(wordcloud)
library(ggplot2)
library(SnowballC)
library(caret)
library(e1071)
library(klaR)
library(arules)
#Reading the data
data <- readLines("lie_detector.csv")
#empty vectors of data
lies <- character(length = length(data))
sentiment <- character(length = length(data))
reviews <- character(length = length(data))
#looping through the lines
for (i in seq_along(data)){
#getting the line
line <- data[i]
#Getting the lie
lies[i] <- substr(line, 1, 1)
#Gettinf the sentiment
sentiment[i] <- substr(line, 3, 3)
#getting the review
review <- substr(line, 6, (nchar(line) - 1))
#Replacing the backslashes
review <- gsub("\\", "", review, fixed = T)
#saving the reviews
reviews[i] <- review
}
#Creating IDs for the reviews
id <- seq_along(reviews)
#Creating the data frame
df <- data.frame(id = id, sentiment = sentiment, lie = lies, review = reviews)
#Getting rid of the first row
df <- df[2:nrow(df), ]
#Converting id to character
df$review <- as.character(df$review)
df$sentiment <- droplevels(df$sentiment)
df$lie <- droplevels(df$lie)
#tokenizing
review_words <- df %>%
dplyr::select(id, sentiment, lie, review) %>%
unnest_tokens(word, review, to_lower = TRUE)
#stemming
review_words$word <- wordStem(review_words$word)
#removing non-alphabetical tokens
review_words <- review_words %>%
filter(!word %in% stop_words$word,
str_detect(word, "^[a-z']+$"))
#Making tfidf
review_words_dtm <- review_words %>%
count(id, sentiment, lie, word) %>%
bind_tf_idf(word, id, n) %>%
dplyr::select(id, sentiment, lie, word, tf_idf) %>%
spread(key = word, value = tf_idf)
#Making all NAs a 0
review_words_dtm[is.na(review_words_dtm)] <- 0
#Making a data frame for only sentiment analysis
sentiment_df <- review_words_dtm %>%
dplyr::select(-id, -lie)
#Replacing na with 0
sentiment_df[,2:ncol(sentiment_df)] <- scale(sentiment_df[,2:ncol(sentiment_df)])
#train test split
set.seed(1000)
train_ix <- createDataPartition(sentiment_df$sentiment, p = 0.75, list = F)
sentiment.train <- sentiment_df[train_ix, ]
sentiment.test <- sentiment_df[-train_ix, ]
#train control
tc <- trainControl(method = "cv", number = 10)
#SVM cost grid
linear.grid = expand.grid(C = c(1, 0.9, 0.8, 0.5, 0.25, 0.1))
#training linear svm
svm.sentiment.linear <- suppressWarnings(train(sentiment ~ ., data = sentiment.train, trControl = tc,
method = "svmLinear", tuneGrid = linear.grid))
preds.linear <- predict(svm.sentiment.linear, sentiment.test)
svm.confmat.linear <- confusionMatrix(preds.linear, sentiment.test$sentiment)
svm.confmat.linear$table
svm.sentiment.linear
nb.sentiment.confmat
nb.sentiment.confmat
nb.sentiment.confmat <- confusionMatrix(preds$class, test.nb$sentiment)
nb <- NaiveBayes(sentiment ~ ., data = sentiment.train, fL = 1, usekernel = T)
#predicting
preds <- predict(nb, sentiment.test[,-1])
confusionMatrix(preds$class, sentiment.test$sentiment)
#Make only binary factors
sentiment.nb <- review_words_dtm %>% dplyr::select(-id, -lie)
sentiment.nb[sentiment.nb > 0] <- "Yes"
sentiment.nb[sentiment.nb == 0] <-"No"
words <- colnames(sentiment.nb)[2:ncol(sentiment.nb)]
sentiment.nb[words] <- lapply(sentiment.nb[words], factor)
#Train and test split
train.nb <- sentiment.nb[train_ix,]
test.nb <- sentiment.nb[-train_ix,]
#Training model
nb.binary <- suppressWarnings(NaiveBayes(sentiment ~ ., data=train.nb, fL = 1, usekernel = F))
preds <- suppressWarnings(predict(nb.binary, test.nb[,-1]))
nb.sentiment.confmat <- confusionMatrix(preds$class, test.nb$sentiment)
nb.sentiment.confmat
svm.confmat.linear
svm.lies.linear
#Making a data frame for only sentiment analysis
lies_df <- review_words_dtm %>%
dplyr::select(-id, -sentiment)
#Replacing na with 0
lies_df[is.na(lies_df)] <- 0
lies_df[,2:ncol(lies_df)] <- scale(lies_df[,2:ncol(lies_df)])
#train test split
set.seed(1000)
lies.train <- lies_df[train_ix, ]
lies.test <- lies_df[-train_ix, ]
#train control
tc <- trainControl(method = "cv", number = 10)
#SVM cost grid
linear.grid <- expand.grid(C = c(1, 0.9, 0.8, 0.5, 0.25, 0.1))
#training linear svm
svm.lies.linear <- suppressWarnings(train(lie ~ ., data = lies.train, trControl = tc,
method = "svmLinear", tuneGrid = linear.grid))
preds.linear <- predict(svm.lies.linear, lies.test)
svm.confmat.linear <- confusionMatrix(preds.linear, lies.test$lie)
svm.confmat.linear$table
svm.lies.linear
svm.confmat.linear$table
svm.confmat.linear$table
svm.confmat.linear <- confusionMatrix(preds.linear, lies.test$lie)
preds.linear <- predict(svm.lies.linear, lies.test)
svm.lies.linear
nb.lies.confmat$table
#TFIDF
nb.grid <- expand.grid(fL = c(1,3,7,11), adjust = 1, usekernel = T)
nb <- suppressWarnings(train(lie ~ ., data = lies.train,
method = "nb", trControl = tc, tuneGrid = nb.grid))
preds <- suppressWarnings(predict(nb, sentiment.test))
confusionMatrix(preds, lies.test$lie)
#Binary
#Make only binary factors
lies.nb <- review_words_dtm %>% dplyr::select(-id, -sentiment)
lies.nb[lies.nb > 0] <- "Yes"
lies.nb[lies.nb == 0] <-"No"
words <- colnames(lies.nb)[2:ncol(lies.nb)]
lies.nb[words] <- lapply(lies.nb[words], factor)
#Train and test split
train.nb <- lies.nb[train_ix,]
test.nb <- lies.nb[-train_ix,]
#Training model
nb.binary <- suppressWarnings(NaiveBayes(lie ~ ., data=train.nb, fL = 1, usekernel = T))
preds <- suppressWarnings(predict(nb.binary, test.nb[,-1]))
nb.lies.confmat <- confusionMatrix(preds$class, test.nb$lie)
nb.lies.confmat$table
svm.lies.linear
svm.confmat.linear
nb.lies.confmat
